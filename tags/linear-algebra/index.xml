<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>linear-algebra on</title><link>https://garden.itodorova.dev/tags/linear-algebra/</link><description>Recent content in linear-algebra on</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><atom:link href="https://garden.itodorova.dev/tags/linear-algebra/index.xml" rel="self" type="application/rss+xml"/><item><title>(In)Consistency</title><link>https://garden.itodorova.dev/notes/math/linear-algebra/InConsistency/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://garden.itodorova.dev/notes/math/linear-algebra/InConsistency/</guid><description>A [[notes/math/linear-algebra/Linear systems|linear system]] is inconsistent if it has no solution, and otherwise it is said to be consistent.
A system of equations whose left-hand sides are linearly independent is always consistent.</description></item><item><title>Basis</title><link>https://garden.itodorova.dev/notes/math/linear-algebra/Basis/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://garden.itodorova.dev/notes/math/linear-algebra/Basis/</guid><description>The concept of basis is closely connected to the idea of [[notes/math/linear-algebra/Linear (In)dependence|linear independence]].
A [[notes/math/linear-algebra/Vector|vector]] [[notes/math/discrete-math/set-theory/Set|set]] is a basis for a space if it:</description></item><item><title>Basis vectors</title><link>https://garden.itodorova.dev/notes/math/linear-algebra/Basis-vectors/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://garden.itodorova.dev/notes/math/linear-algebra/Basis-vectors/</guid><description>There are a few special [[notes/math/linear-algebra/Unit Vector|unit vectors]] used in vector calculus and in linear algebra, which are called the standard basis vectors.</description></item><item><title>Cramer's rule</title><link>https://garden.itodorova.dev/notes/math/linear-algebra/Cramers-rule/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://garden.itodorova.dev/notes/math/linear-algebra/Cramers-rule/</guid><description>Cramer’s rule is a simple little rule that lets us use [[notes/math/linear-algebra/Determinant|determinants]] to solve a [[notes/math/linear-algebra/Linear systems|system of linear equations]].</description></item><item><title>Determinant</title><link>https://garden.itodorova.dev/notes/math/linear-algebra/Determinant/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://garden.itodorova.dev/notes/math/linear-algebra/Determinant/</guid><description>Determinants are mathematical objects that are very useful in the analysis and solution of [[notes/math/linear-algebra/Linear systems|systems of linear equations]]. The determinant of a [[notes/math/linear-algebra/Matrix|matrix]] defines whether the matrix is invertible or not/has a unique solution.</description></item><item><title>Elimination matrix</title><link>https://garden.itodorova.dev/notes/math/linear-algebra/Elimination-matrix/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://garden.itodorova.dev/notes/math/linear-algebra/Elimination-matrix/</guid><description>The entire collection of all the [[notes/math/linear-algebra/Simple row operation|simple row operations]] we perform to change a [[notes/math/linear-algebra/Matrix|matrix]] into [[notes/math/linear-algebra/Row-echelon form#^3c454c| reduced row-echelon]] form can be brought together in one matrix, and we call that matrix the elimination matrix, $E$ (елементарна матрица).</description></item><item><title>Gaus-Jordan Elimination</title><link>https://garden.itodorova.dev/notes/math/linear-algebra/Gaus-Jordan-Elimination/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://garden.itodorova.dev/notes/math/linear-algebra/Gaus-Jordan-Elimination/</guid><description>An algorithm that uses [[notes/math/linear-algebra/Simple row operation|simple row operations]] to bring a [[notes/math/linear-algebra/Matrix|matrix]] into [[notes/math/linear-algebra/Row-echelon form|row-echelon form]].
Steps:
optional: Pull out any scalars from each row in the matrix.</description></item><item><title>Identity matrix</title><link>https://garden.itodorova.dev/notes/math/linear-algebra/Identity-matrix/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://garden.itodorova.dev/notes/math/linear-algebra/Identity-matrix/</guid><description>The indentity matrix is a square [[notes/math/linear-algebra/Matrix|matrix]] that when multiplied by another matrix you don&amp;rsquo;t change the value of the other matrix.</description></item><item><title>Linear (In)dependence</title><link>https://garden.itodorova.dev/notes/math/linear-algebra/Linear-Independence/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://garden.itodorova.dev/notes/math/linear-algebra/Linear-Independence/</guid><description>Independence Any $2$ two-dimensional linearly independent vectors will span $\mathbb{R}^2$. The two-dimensional [[notes/math/linear-algebra/Basis vectors|basis vectors]] $\hat{i}$ and $\hat{j}$ are linearly independent, which is why they span $\mathbb{R}^2$.</description></item><item><title>Linear combinations of the basis vectors</title><link>https://garden.itodorova.dev/notes/math/linear-algebra/Linear-combinations-of-the-basis-vectors/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://garden.itodorova.dev/notes/math/linear-algebra/Linear-combinations-of-the-basis-vectors/</guid><description>Using the [[notes/math/linear-algebra/Basis vectors|basis vectors]] for $\mathbb{R}^2$ as a starting point, we can actually build every vector in two-dimensional space, simply by adding scaled combinations of $\hat{i}$ and $\hat{j}$.</description></item><item><title>Linear systems</title><link>https://garden.itodorova.dev/notes/math/linear-algebra/Linear-systems/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://garden.itodorova.dev/notes/math/linear-algebra/Linear-systems/</guid><description>A linear system is a system of equations, defined for a set of unknown variables, where each of the variables is linear (the variables are first degree, or raised to the power of $1$).</description></item><item><title>Matrix</title><link>https://garden.itodorova.dev/notes/math/linear-algebra/Matrix/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://garden.itodorova.dev/notes/math/linear-algebra/Matrix/</guid><description>The [[notes/math/linear-algebra/Linear systems|Linear Systems]]
$$ \begin{align} 3x + 2y = 7 \ x - 6y = 0 \end{align} $$
can be represented as a matrix.</description></item><item><title>Matrix Addition</title><link>https://garden.itodorova.dev/notes/math/linear-algebra/Matrix-Addition/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://garden.itodorova.dev/notes/math/linear-algebra/Matrix-Addition/</guid><description>Adding two [[notes/math/linear-algebra/Matrix|matrices]] is defined only if both matrices have the same dimensions.
$$ \begin{bmatrix} a &amp;amp; b \ c &amp;amp; d \end{bmatrix}</description></item><item><title>Matrix Multiplication</title><link>https://garden.itodorova.dev/notes/math/linear-algebra/Matrix-Multiplication/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://garden.itodorova.dev/notes/math/linear-algebra/Matrix-Multiplication/</guid><description>[[notes/math/linear-algebra/Matrix]] multiplication is:
NOT commutative - $A\cdot B \neq B\cdot A$ associative - $(AB)C = A(BC)$ distributive - $A(B + C) = AB + AC$ To multiply a matrix by another matrix the number of columns in the first matrix must be equal to the number of rows in the second matrix.</description></item><item><title>Matrix Rank</title><link>https://garden.itodorova.dev/notes/math/linear-algebra/Matrix-Rank/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://garden.itodorova.dev/notes/math/linear-algebra/Matrix-Rank/</guid><description>Тhe rank of a [[notes/math/linear-algebra/Matrix|matrix]] $A$ is the dimension of the [[notes/math/linear-algebra/Vector|vector]] space generated (or [[notes/math/linear-algebra/Span of a vector set|spanned]]) by its columns.</description></item><item><title>Matrix Scalar Division</title><link>https://garden.itodorova.dev/notes/math/linear-algebra/Matrix-Scalar-Division/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://garden.itodorova.dev/notes/math/linear-algebra/Matrix-Scalar-Division/</guid><description>[[notes/math/linear-algebra/Matrix|Matrices]] can be divided by a scalar like this:
$$ \frac{1}{6} \cdot \begin{bmatrix} a &amp;amp; b &amp;amp; c \ d &amp;amp; f &amp;amp; e \end{bmatrix} \begin{bmatrix} \frac{1}{6}a &amp;amp; \frac{1}{6}b &amp;amp; \frac{1}{6}c \ \frac{1}{6}d &amp;amp; \frac{1}{6}f &amp;amp; \frac{1}{6}e \end{bmatrix} $$</description></item><item><title>Matrix Scalar Multiplication</title><link>https://garden.itodorova.dev/notes/math/linear-algebra/Matrix-Scalar-Multiplication/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://garden.itodorova.dev/notes/math/linear-algebra/Matrix-Scalar-Multiplication/</guid><description>Multiplying [[notes/math/linear-algebra/Matrix|matrix]] by a scalar can be done like:
$$ 3 \cdot \begin{bmatrix} a &amp;amp; b &amp;amp; c \ d &amp;amp; f &amp;amp; e \end{bmatrix} \begin{bmatrix} 3a &amp;amp; 3b &amp;amp; 3c \ 3d &amp;amp; 3f &amp;amp; 3e \end{bmatrix} $$</description></item><item><title>Matrix Subtraction</title><link>https://garden.itodorova.dev/notes/math/linear-algebra/Matrix-Subtraction/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://garden.itodorova.dev/notes/math/linear-algebra/Matrix-Subtraction/</guid><description>Subtracting [[notes/math/linear-algebra/Matrix|matrices]] is only defined for matrices with the same dimensions.
$$ \begin{bmatrix} a &amp;amp; b \ c &amp;amp; d \end{bmatrix} \begin{bmatrix} e &amp;amp; f \ g &amp;amp; h \end{bmatrix} \begin{bmatrix} a - e &amp;amp; b - f \ c - g &amp;amp; d - h \end{bmatrix} $$</description></item><item><title>Matrix Transposition</title><link>https://garden.itodorova.dev/notes/math/linear-algebra/Matrix-Transposition/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://garden.itodorova.dev/notes/math/linear-algebra/Matrix-Transposition/</guid><description>Тhe transpose of a [[notes/math/linear-algebra/Matrix|matrix]] is an operator which flips a matrix over its diagonal; that is, it switches the row and column indices of the matrix $A$ by producing another matrix, often denoted by $A^T$.</description></item><item><title>Number of solutions to the linear system</title><link>https://garden.itodorova.dev/notes/math/linear-algebra/Number-of-solutions-to-the-linear-system/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://garden.itodorova.dev/notes/math/linear-algebra/Number-of-solutions-to-the-linear-system/</guid><description>[[notes/math/linear-algebra/Linear systems|Linear systems]] can have:
One solution (called the unique solution) $$ \begin{bmatrix} 1 &amp;amp; 0 &amp;amp; 0 &amp;amp; \bigm| &amp;amp; a\ 0 &amp;amp; 1 &amp;amp; 0 &amp;amp; \bigm| &amp;amp; b\ 0 &amp;amp; 0 &amp;amp; 1 &amp;amp; \bigm| &amp;amp; c \end{bmatrix} \rightarrow (x, y, z) = (a, b, c) $$</description></item><item><title>Parallelogram</title><link>https://garden.itodorova.dev/notes/math/linear-algebra/Parallelogram/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://garden.itodorova.dev/notes/math/linear-algebra/Parallelogram/</guid><description>успоредник
Let $A$ be a [[notes/math/linear-algebra/Matrix|matrix]] if you separate it into its [[notes/math/linear-algebra/Vector|column vectors]], and call them $v_1$ and $v_2$, then you can plot $v_1$ and $v_2$ in the $xy$-plane, and create a parallelogram using them as two of its adjacent sides.</description></item><item><title>Pivot entries</title><link>https://garden.itodorova.dev/notes/math/linear-algebra/Pivot-entries/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://garden.itodorova.dev/notes/math/linear-algebra/Pivot-entries/</guid><description>pivot entry - водещ елемент;
The non-zero element in each row of a [[notes/math/linear-algebra/Matrix|matrix]].
$$ \begin{bmatrix} 4 &amp;amp; 1 &amp;amp; 0 &amp;amp; \bigm| &amp;amp; 17\ 0 &amp;amp; 2 &amp;amp; 5 &amp;amp; \bigm| &amp;amp; 10\ 0 &amp;amp; 0 &amp;amp; -3 &amp;amp; \bigm| &amp;amp; 2 \end{bmatrix} $$</description></item><item><title>Rouché–Capelli theorem</title><link>https://garden.itodorova.dev/notes/math/linear-algebra/Rouch%C3%A9Capelli-theorem/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://garden.itodorova.dev/notes/math/linear-algebra/Rouch%C3%A9Capelli-theorem/</guid><description>A [[notes/math/linear-algebra/Linear systems|system of linear equations]] with $n$ variables has a solution if and only if the [[notes/math/linear-algebra/Matrix Rank|the rank]] of its coefficient matrix $A$ is equal to the rank of its [[notes/math/linear-algebra/Matrix|augmented matrix]] $[A | b]$.</description></item><item><title>Row-echelon form</title><link>https://garden.itodorova.dev/notes/math/linear-algebra/Row-echelon-form/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://garden.itodorova.dev/notes/math/linear-algebra/Row-echelon-form/</guid><description>A [[notes/math/linear-algebra/Matrix|matrix]] is in row-echelon form (ref) if:
All the [[notes/math/linear-algebra/Pivot entries|pivot entries]] are equal to $1$ Any row&amp;rsquo;s that consist of only $0$s are at the bottom of the matrix The pivot in each row sists in a column to the right of the column that houses the pivot in the row above it.</description></item><item><title>Simple row operation</title><link>https://garden.itodorova.dev/notes/math/linear-algebra/Simple-row-operation/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://garden.itodorova.dev/notes/math/linear-algebra/Simple-row-operation/</guid><description>Performing simple row operations leads to finding solution to linear systems represented as a [[notes/math/linear-algebra/Matrix|matrix]] or finding the inverse of a [[notes/math/linear-algebra/Matrix|matrix]].</description></item><item><title>Span of a vector set</title><link>https://garden.itodorova.dev/notes/math/linear-algebra/Span-of-a-vector-set/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://garden.itodorova.dev/notes/math/linear-algebra/Span-of-a-vector-set/</guid><description>The span of a [[notes/math/discrete-math/set-theory/Set|set]] of [[notes/math/linear-algebra/Vector|vectors]] is the collection of all vectors which can be represented by some [[notes/math/linear-algebra/Linear combinations of the basis vectors|linear combination]] of the set.</description></item><item><title>Subspace</title><link>https://garden.itodorova.dev/notes/math/linear-algebra/Subspace/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://garden.itodorova.dev/notes/math/linear-algebra/Subspace/</guid><description>Within spaces ( $\mathbb{R}^2, \mathbb{R}^3,\mathbb{R}^4,\dots,\mathbb{R}^n$), we can define subspaces.
To give na example, a subspace of $\mathbb{R}^2$ is a set of two-dimensional [[notes/math/linear-algebra/Vector|vectors]] within $\mathbb{R}^2$, where the set meets three specific conditions:</description></item><item><title>Symmetric Matrix</title><link>https://garden.itodorova.dev/notes/math/linear-algebra/Symmetric-Matrix/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://garden.itodorova.dev/notes/math/linear-algebra/Symmetric-Matrix/</guid><description>A symmetric matrix is a square matrix that is equal to its [[notes/math/linear-algebra/Matrix Transposition|transpose]].
The entries of a symmetric matrix are symmetric with respect to the main diagonal.</description></item><item><title>Unit Vector</title><link>https://garden.itodorova.dev/notes/math/linear-algebra/Unit-Vector/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://garden.itodorova.dev/notes/math/linear-algebra/Unit-Vector/</guid><description>Any [[notes/math/linear-algebra/Vector|vector]] of a magnitude of $1$ is called a unit vector, $\overrightarrow{u}$. In general, a unit vector doesn&amp;rsquo;t have to point in a particular direction.</description></item><item><title>Upper and Lower triangular matrix</title><link>https://garden.itodorova.dev/notes/math/linear-algebra/Upper-and-Lower-triangular-matrix/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://garden.itodorova.dev/notes/math/linear-algebra/Upper-and-Lower-triangular-matrix/</guid><description>Upper triangular [[notes/math/linear-algebra/Matrix|matrices]] are matrices in which all entries below the main diagonal are $0$.
$$ A= \begin{bmatrix} 1 &amp;amp; 2 &amp;amp; 3 \ 0 &amp;amp; -2 &amp;amp; 0 \ 0 &amp;amp; 0 &amp;amp; 5 \end{bmatrix}$$</description></item><item><title>Vector</title><link>https://garden.itodorova.dev/notes/math/linear-algebra/Vector/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://garden.itodorova.dev/notes/math/linear-algebra/Vector/</guid><description>A vector has two pieces of infromation contained within it:
the direction in which the vector points the magnitude of the vector (which is just the length of the vector) Vector expressions: $$ \overrightarrow{a} = (3, 4) $$ $$ \overrightarrow{b} = (3, 4, 5) $$</description></item><item><title>Vector Operations</title><link>https://garden.itodorova.dev/notes/math/linear-algebra/Vector-Operations/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://garden.itodorova.dev/notes/math/linear-algebra/Vector-Operations/</guid><description>Sum of Vectors To add vectors, just add their corresponding components. Given $\overrightarrow{a} = (3, 4)$ and $\overrightarrow{b} = (-1, 2)$, the sum of the vectors is $$ \overrightarrow{a} + \overrightarrow{b} = (3 + (-1), 4 + 2) = (2, 6) $$ Graphically, we can see that adding vectors means connecting the terminal point of one to the tail of the other.</description></item><item><title>Zero matrix</title><link>https://garden.itodorova.dev/notes/math/linear-algebra/Zero-matrix/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://garden.itodorova.dev/notes/math/linear-algebra/Zero-matrix/</guid><description>Any [[notes/math/linear-algebra/Matrix|matrix]] that&amp;rsquo;s full of only zeros, regardless of the dimensions of the matrix, we call a zero matrix. We always name the zero matrix with a capital $O$.</description></item></channel></rss>